<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="TRUCE-AV provides a multimodal dataset for trust and comfort estimation in autonomous vehicles">
  <meta name="keywords" content="truceav, truce-av, autonomous vehicles, trust estimation, comfort estimation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dataset: Trust and Comfort Estimation in AV</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" 
  rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css"> 
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="container has-text-centered">
          <h1 class="title is-1 publication-title">TRUCE-AV: A Multimodal dataset for Trust and Comfort Estimation in Autonomous Vehicles</h1>
          <h2 class="subtitle">ECAI 2025</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/aditi-bhalla-b212a9186/">Aditi Bhalla</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=PfZIfBoAAAAJ&hl=en">Christian Hellert</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.edu.sot.tum.de/hctl/prof-dr-enkelejda-kasneci/">Enkelejda Kasneci</a><sup>1</sup></span>
            <span class="author-block">
              <a href="#">Nastassja Becker</a><sup>2</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Technical University of Munich,</span>
            <span class="author-block"><sup>2</sup>Continental Automotive Technologies GmbH</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2508.17880"
                 class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                 </span>
                 <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2508.17880"
                 class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                  <i class="ai ai-arxiv"></i>
                 </span>
                 <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2508.17880"
                 class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                  <i class="far fa-images"></i>
                 </span>
                 <span>Dataset</span>
                </a>
              </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/Models.png" 
           alt="Teaser image"
           style="max-width:90%; height:auto; display:block; margin:0 auto;" />
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
        <p>
          Understanding and estimating driver trust and comfort are essential for the safety and widespread acceptance of autonomous vehicles.
          Existing works analyze user trust and comfort separately, with limited real-time assessment and insufficient multimodal data.
          Therefore, we propose a <b>novel multimodal dataset called TRUCE-AV, focusing on trust and comfort estimation in autonomous vehicles</b>.
        </p> 
        <p>
          The dataset collects real-time trust votes and continuous comfort ratings of 31 participants during a simulator-based fully autonomous driving.
          Simultaneously, physiological signals, such as heart rate, gaze, and emotions, along with environmental data
          (e.g., vehicle speed, nearby vehicle positions, and velocity), are recorded throughout the drives.
          Standard pre- and post-drive questionnaires were also administered to assess participants' trust in automation and overall well-being,
          enabling the correlation of subjective assessments with real-time responses.
        </p>
        <p>
          Our dataset enables the development of adaptive AV systems capable of dynamically responding to user trust and comfort levels non-invasively,
          ultimately enhancing safety, user experience, and human-centered vehicle design. 
        </p>
        <p>
          To demonstrate the utility of our dataset, we evaluated various machine learning models for trust and comfort estimation using physiological data. 
          Our analysis showed that tree-based models like Random Forest and XGBoost and non-linear models such as KNN and MLP regressor achieved the best performance for trust classification and comfort regression.
          Additionally, we identified key features that contribute to these estimations by using SHAP analysis on the top-performing models.
        </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Dataset Description -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Dataset</h2>
        <p>
          Description of the dataset goes here.
        </p>
      </div>
    </div>


    <!-- Benchmark Results -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <p>
          Results go here. 
        </p>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">BibTeX</h2>
    <pre><code>@misc{bhalla2025truceavmultimodaldatasettrust,
      title={TRUCE-AV: A Multimodal dataset for Trust and Comfort Estimation in Autonomous Vehicles}, 
      author={Aditi Bhalla and Christian Hellert and Enkelejda Kasneci and Nastassja Becker},
      year={2025},
      eprint={2508.17880},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2508.17880}, 
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container has-text-centered">
    <p>
      Website inspired by <a href="https://nerfies.github.io">Nerfies</a>.
    </p>
  </div>
</footer>

</body>
</html>
